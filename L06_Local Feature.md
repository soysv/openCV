## 1ï¸âƒ£ SIFTë¥¼ ì´ìš©í•œ íŠ¹ì§•ì  ê²€ì¶œ ë° ì‹œê°í™”
### ğŸŒ€ ê³¼ì œ ì„¤ëª…
- ì†Œë²¨(Sobel) í•„í„°ë¥¼ ì‚¬ìš©í•´ ì—£ì§€ë¥¼ ê²€ì¶œ
<br>
  
### ğŸ“Œ ê°œë…
- ì†Œë²¨ í•„í„°ë¥¼ ì´ìš©í•´ X, Y ë°©í–¥ì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°
- ê¸°ìš¸ê¸°ë¥¼ ì¡°í•©í•˜ì—¬ ì—ì§€ ê°•ë„(edge magnitude) ê³„ì‚°
- ê²€ì¶œëœ ì—£ì§€ë¥¼ ì‹œê°í™”
<br>

### ğŸ’» ì£¼ìš” ì½”ë“œ
<p>âœ” <b>ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° </b><code>cv.imread(image_path)</code><br></p>
<p>âœ” <b>ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜</b> <code>cv.cvtColor(image, cv.COLOR_BGR2GRAY)</code><br>
<p>âœ” <b>ì†Œë²¨ í•„í„° ì ìš©</b> <code>cv.Sobel(src, ddepth, dx, dy, ksize)</code><br>
<p>âœ” <b>ì—ì§€ ê°•ë„ ê³„ì‚°</b> <code>edge_magnitude = cv.magnitude(sobel_x, sobel_y)</code><br>
<p>âœ” <b>ì´ë¯¸ì§€ ì‹œê°í™”</b> <code>cv.imshow()</code><br>
<br>

<br>



<details>
  <summary><b> ğŸ§¿ í´ë¦­í•´ì„œ ì½”ë“œ ë³´ê¸° </b></summary>
  
  ```python
import cv2 as cv
import matplotlib.pyplot as plt

# ì´ë¯¸ì§€ ë¡œë“œ
image_path = 'C:/Users/82107/Desktop/cv/mot_color70.jpg'
image = cv.imread(image_path)
gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

# SIFT ê°ì²´ ìƒì„± (íŠ¹ì§•ì  ê°œìˆ˜ ì¡°ì ˆ ê°€ëŠ¥)
sift = cv.SIFT_create(nfeatures=500)

# íŠ¹ì§•ì  ê²€ì¶œ ë° ê¸°ìˆ ì ê³„ì‚°
keypoints, descriptors = sift.detectAndCompute(gray, None)

# íŠ¹ì§•ì  ì‹œê°í™”
image_with_keypoints = cv.drawKeypoints(image, keypoints, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

# ì´ë¯¸ì§€ ì¶œë ¥
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))
plt.title('Original Image')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(cv.cvtColor(image_with_keypoints, cv.COLOR_BGR2RGB))
plt.title('SIFT Keypoints')
plt.axis('off')

plt.show()

 ```
</details>

<br>

### ğŸ•µâ€â™€ ê²°ê³¼í™”ë©´
![ê²°ê³¼ì´ë¯¸ì§€](./data/6_1.png)

<br>
<br>

## 2ï¸âƒ£ SIFTë¥¼ ì´ìš©í•œ ë‘ ì˜ìƒ ê°„ íŠ¹ì§•ì  ë§¤ì¹­
### ğŸŒ€ ê³¼ì œ ì„¤ëª…
- ì´ì§„í™”ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ <b>íŒ½ì°½(Dilation), ì¹¨ì‹(Erosion), ì—´ë¦¼(Opening), ë‹«í˜(Closing) ì—°ì‚°</b>ì„ ìˆ˜í–‰í•˜ì—¬<br> ë…¸ì´ì¦ˆ ì œê±° ë° í˜•íƒœ ë³´ì •
<br>

### ğŸ“Œ ê°œë…
- ìºë‹ˆ ì—ì§€ ê²€ì¶œì„ ì´ìš©í•´ ì—£ì§€ë¥¼ ì¶”ì¶œ
- í—ˆí”„ ë³€í™˜(Hough Transform)ì„ ì´ìš©í•´ ì§ì„ ì„ ê²€ì¶œ
- ê²€ì¶œëœ ì§ì„ ì„ ì›ë³¸ ì´ë¯¸ì§€ì— í‘œì‹œ
<br>

### ğŸ’» ì£¼ìš” ì½”ë“œ
<p>âœ” <b>ìºë‹ˆ ì—ì§€ ê²€ì¶œ</b> <code>cv.Canny(image, threshold1, threshold2)</code><br>
<p>âœ” <b>í—ˆí”„ ë³€í™˜ì„ ì‚¬ìš©í•œ ì§ì„  ê²€ì¶œ</b> <code>cv.HoughLinesP(image, rho, theta, threshold, minLineLength, maxLineGap)</code><br>
<p>âœ” <b>ê²€ì¶œëœ ì§ì„ ì„ ì›ë³¸ ì´ë¯¸ì§€ì— ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ</b> <code>cv.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)</code><br>
<br>

<details>
  <summary><b> ğŸ§¿ í´ë¦­í•´ì„œ ì½”ë“œ ë³´ê¸° </b></summary>

  ```python
import cv2 as cv
import matplotlib.pyplot as plt

# ì´ë¯¸ì§€ ë¡œë“œ
image1_path = 'C:/Users/82107/Desktop/cv/mot_color70.jpg'
image2_path = 'C:/Users/82107/Desktop/cv/mot_color83.jpg'
image1 = cv.imread(image1_path)
image2 = cv.imread(image2_path)
gray1 = cv.cvtColor(image1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(image2, cv.COLOR_BGR2GRAY)

# SIFT ê°ì²´ ìƒì„±
sift = cv.SIFT_create()

# íŠ¹ì§•ì  ê²€ì¶œ ë° ê¸°ìˆ ì ê³„ì‚°
keypoints1, descriptors1 = sift.detectAndCompute(gray1, None)
keypoints2, descriptors2 = sift.detectAndCompute(gray2, None)

# BFMatcher ìƒì„± ë° ë§¤ì¹­ ìˆ˜í–‰
bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)
matches = bf.match(descriptors1, descriptors2)

# ë§¤ì¹­ ê²°ê³¼ ì •ë ¬ (ê±°ë¦¬ìˆœ)
matches = sorted(matches, key=lambda x: x.distance)

# ë§¤ì¹­ ê²°ê³¼ ì‹œê°í™”
image_matches = cv.drawMatches(image1, keypoints1, image2, keypoints2, matches[:50], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# ê²°ê³¼ ì¶œë ¥
plt.figure(figsize=(12, 6))
plt.imshow(cv.cvtColor(image_matches, cv.COLOR_BGR2RGB))
plt.title('SIFT Feature Matching')
plt.axis('off')
plt.show()

 ```
</details>

<br>

### ğŸ•µâ€â™€ ê²°ê³¼í™”ë©´
![ê²°ê³¼ì´ë¯¸ì§€](./data/6_2.png)

<br>
<br>

## 3ï¸âƒ£ í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ì •í•©(Image Alignment)
### ğŸŒ€ ê³¼ì œ ì„¤ëª…
- GrabCut ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ì—ì„œ ê°ì²´(ì „ê²½)ì™€ ë°°ê²½ì„ ë¶„ë¦¬
<br>

### ğŸ“Œ ê°œë…
- ì´ˆê¸° ì‚¬ê°í˜•(rect)ì„ ì„¤ì •í•˜ì—¬ ê´€ì‹¬ ì˜ì—­ ì§€ì •
- GrabCut ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ ë°°ê²½ê³¼ ì „ê²½ ë¶„ë¦¬
- ë§ˆìŠ¤í¬(mask) ì²˜ë¦¬ë¥¼ í†µí•´ ì „ê²½ë§Œ ë‚¨ê¹€
<br>

### ğŸ’» ì£¼ìš” ì½”ë“œ
<p> âœ” <b> ì´ˆê¸° ë§ˆìŠ¤í¬ ìƒì„±</b> <code>np.zeros(image.shape[:2], np.uint8)</code><br>
<p> âœ” <b> ë°°ê²½ ëª¨ë¸ê³¼ ì „ê²½ ëª¨ë¸ ì´ˆê¸°í™”</b> <code>bgdModel = np.zeros((1, 65), np.float64)</code><br>
<p> - cv.grabCut() í•¨ìˆ˜ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì „ê²½(foreground)ê³¼ ë°°ê²½(background) ëª¨ë¸ì„ ì €ì¥í•  ë°°ì—´ <br>
<p> - 65: OpenCVì—ì„œ ì •í•´ì§„ GMM(Gaussian Mixture Model) íŒŒë¼ë¯¸í„° ê°œìˆ˜<br>
<p> âœ” <b> ë§ˆìŠ¤í¬ ì²˜ë¦¬í•˜ì—¬ ë°°ê²½ ì œê±° </b> <code>mask2 = np.where((mask == cv.GC_BGD) | (mask == cv.GC_PR_BGD), 0, 1).astype('uint8')
</code>
<p> - cv.GC_BGD(0): í™•ì‹¤í•œ ë°°ê²½
<p> - cv.GC_PR_BGD(2): ê°€ëŠ¥ì„±ì´ ë†’ì€ ë°°ê²½
<p> - cv.GC_FGD(1): í™•ì‹¤í•œ ì „ê²½
<p> - cv.GC_PR_FGD(3): ê°€ëŠ¥ì„±ì´ ë†’ì€ ì „ê²½
<p> - ë°°ê²½ í”½ì…€ì„ ì œê±°í•˜ê³  ì „ê²½ë§Œ ë‚¨ê¹€
<br>
<br>


<details>
  <summary><b> ğŸ§¿ í´ë¦­í•´ì„œ ì½”ë“œ ë³´ê¸° </b></summary>

  ```python
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt

# ì´ë¯¸ì§€ ë¡œë“œ
image1_path = 'C:/Users/82107/Desktop/cv/img1.jpg'
image2_path = 'C:/Users/82107/Desktop/cv/img2.jpg'
image1 = cv.imread(image1_path)
image2 = cv.imread(image2_path)

# ì´ë¯¸ì§€ ë¡œë“œ í™•ì¸
if image1 is None or image2 is None:
    print("Error: One or both images could not be loaded. Check the file paths.")
    exit()

# ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
gray1 = cv.cvtColor(image1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(image2, cv.COLOR_BGR2GRAY)

# SIFT ê°ì²´ ìƒì„±
sift = cv.SIFT_create()

# íŠ¹ì§•ì  ê²€ì¶œ ë° ê¸°ìˆ ì ê³„ì‚°
keypoints1, descriptors1 = sift.detectAndCompute(gray1, None)
keypoints2, descriptors2 = sift.detectAndCompute(gray2, None)

# BFMatcher ìƒì„± ë° ë§¤ì¹­ ìˆ˜í–‰
bf = cv.BFMatcher(cv.NORM_L2)
matches = bf.knnMatch(descriptors1, descriptors2, k=2)

# ì¢‹ì€ ë§¤ì¹­ì  ì„ íƒ (ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ ì ìš©)
good_matches = []
ratio_thresh = 0.75
for m, n in matches:
    if m.distance < ratio_thresh * n.distance:
        good_matches.append(m)

# ë§¤ì¹­ ê°œìˆ˜ í™•ì¸
print(f"Number of good matches: {len(good_matches)}")

# ìµœì†Œí•œì˜ ë§¤ì¹­ì  í•„ìš”
if len(good_matches) > 10:
    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
    
    # í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°
    H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)

    # í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
    if H is None:
        print("Error: Homography calculation failed.")
        exit()
    
    # ì´ë¯¸ì§€ ì •í•©
    h, w = image1.shape[:2]
    aligned_image = cv.warpPerspective(image1, H, (w, h))
    
    # ê²°ê³¼ ì¶œë ¥
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 3, 1)
    plt.imshow(cv.cvtColor(image1, cv.COLOR_BGR2RGB))
    plt.title('Original Image')
    plt.axis('off')
    
    plt.subplot(1, 3, 2)
    plt.imshow(cv.cvtColor(image2, cv.COLOR_BGR2RGB))
    plt.title('Target Image')
    plt.axis('off')
    
    plt.subplot(1, 3, 3)
    plt.imshow(cv.cvtColor(aligned_image, cv.COLOR_BGR2RGB))
    plt.title('Aligned Image')
    plt.axis('off')
    
    plt.show(block=True)  # ì°½ì´ ë°”ë¡œ ë‹«íˆì§€ ì•Šë„ë¡ ì„¤ì •
else:
    print("Not enough matches found to compute homography.")

 ```
</details>

<br>

### ğŸ•µâ€â™€ ê²°ê³¼í™”ë©´
![ê²°ê³¼ì´ë¯¸ì§€](./data/6_3.png)
